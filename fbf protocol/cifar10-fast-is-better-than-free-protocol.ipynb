{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --quiet adversarial-robustness-toolbox","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T18:44:53.123521Z","iopub.execute_input":"2025-11-17T18:44:53.123826Z","iopub.status.idle":"2025-11-17T18:44:58.493587Z","shell.execute_reply.started":"2025-11-17T18:44:53.123800Z","shell.execute_reply":"2025-11-17T18:44:58.492577Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom art.estimators.classification import PyTorchClassifier\nfrom art.defences.trainer import AdversarialTrainerFBFPyTorch\nfrom art.utils import load_cifar10\nfrom art.attacks.evasion import ProjectedGradientDescent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T18:45:37.607372Z","iopub.execute_input":"2025-11-17T18:45:37.608081Z","iopub.status.idle":"2025-11-17T18:45:43.536662Z","shell.execute_reply.started":"2025-11-17T18:45:37.608044Z","shell.execute_reply":"2025-11-17T18:45:43.536065Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"def prepare_data():\n    \"\"\"Load and prepare CIFAR-10 data.\"\"\"\n    print(\"Loading CIFAR-10 dataset...\")\n\n    # Load CIFAR-10\n    (x_train, y_train), (x_test, y_test), _, _ = load_cifar10()\n\n    # Convert to PyTorch format (N, C, H, W)\n    x_train = x_train.transpose(0, 3, 1, 2).astype(\"float32\")\n    x_test = x_test.transpose(0, 3, 1, 2).astype(\"float32\")\n\n    print(f\"Training data shape: {x_train.shape}\")\n    print(f\"Training labels shape: {y_train.shape}\")\n    print(f\"Test data shape: {x_test.shape}\")\n    print(f\"Test labels shape: {y_test.shape}\")\n\n    return (x_train, y_train), (x_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T18:55:28.960023Z","iopub.execute_input":"2025-11-17T18:55:28.960806Z","iopub.status.idle":"2025-11-17T18:55:28.966080Z","shell.execute_reply.started":"2025-11-17T18:55:28.960778Z","shell.execute_reply":"2025-11-17T18:55:28.965299Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = prepare_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T18:55:29.274602Z","iopub.execute_input":"2025-11-17T18:55:29.274849Z","iopub.status.idle":"2025-11-17T18:55:30.443335Z","shell.execute_reply.started":"2025-11-17T18:55:29.274830Z","shell.execute_reply":"2025-11-17T18:55:30.442556Z"}},"outputs":[{"name":"stdout","text":"Loading CIFAR-10 dataset...\nTraining data shape: (50000, 3, 32, 32)\nTraining labels shape: (50000, 10)\nTest data shape: (10000, 3, 32, 32)\nTest labels shape: (10000, 10)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"norm_mean = np.array([0.4914, 0.4822, 0.4465]).reshape(3, 1, 1)\nnorm_std = np.array([0.2471, 0.2435, 0.2616]).reshape(3, 1, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T18:55:30.444502Z","iopub.execute_input":"2025-11-17T18:55:30.444751Z","iopub.status.idle":"2025-11-17T18:55:30.448736Z","shell.execute_reply.started":"2025-11-17T18:55:30.444733Z","shell.execute_reply":"2025-11-17T18:55:30.447838Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"norm_mean = np.tile(norm_mean, (1, 32, 32))\nnorm_std = np.tile(norm_std, (1, 32, 32))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T18:55:30.449476Z","iopub.execute_input":"2025-11-17T18:55:30.449702Z","iopub.status.idle":"2025-11-17T18:55:30.465628Z","shell.execute_reply.started":"2025-11-17T18:55:30.449688Z","shell.execute_reply":"2025-11-17T18:55:30.464908Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    \"\"\"\n    A simple CNN architecture for CIFAR-10 classification.\n    \"\"\"\n\n    def __init__(self, num_classes: int = 10) -> None:\n        super(SimpleCNN, self).__init__()\n\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        self.fc_layers = nn.Sequential(\n            nn.Linear(64 * 8 * 8, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc_layers(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T18:52:26.145968Z","iopub.execute_input":"2025-11-17T18:52:26.146929Z","iopub.status.idle":"2025-11-17T18:52:26.154401Z","shell.execute_reply.started":"2025-11-17T18:52:26.146900Z","shell.execute_reply":"2025-11-17T18:52:26.153666Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def init_model_weights(module: nn.Module) -> None:\n    \"\"\"Initialize model weights.\"\"\"\n    if isinstance(module, nn.Conv2d):\n        n = module.kernel_size[0] * module.kernel_size[1] * module.out_channels\n        module.weight.data.normal_(0, math.sqrt(2.0 / n))\n        if module.bias is not None:\n            module.bias.data.zero_()\n\n    elif isinstance(module, nn.Linear):\n        nn.init.xavier_uniform_(module.weight)\n        if module.bias is not None:\n            module.bias.data.zero_()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T18:53:39.519515Z","iopub.execute_input":"2025-11-17T18:53:39.519817Z","iopub.status.idle":"2025-11-17T18:53:39.524852Z","shell.execute_reply.started":"2025-11-17T18:53:39.519795Z","shell.execute_reply":"2025-11-17T18:53:39.524221Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def create_classifier(model, norm_mean, norm_std, device):\n    \"\"\"Create ART PyTorchClassifier.\"\"\"\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n\n    # Create classifier\n    classifier = PyTorchClassifier(\n        model=model,\n        clip_values=(0.0, 1.0),\n        preprocessing=(norm_mean, norm_std),\n        loss=criterion,\n        optimizer=optimizer,\n        input_shape=(3, 32, 32),\n        nb_classes=10,\n        device_type=device\n    )\n\n    return classifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T18:56:59.886410Z","iopub.execute_input":"2025-11-17T18:56:59.887275Z","iopub.status.idle":"2025-11-17T18:56:59.892043Z","shell.execute_reply.started":"2025-11-17T18:56:59.887232Z","shell.execute_reply":"2025-11-17T18:56:59.891294Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T19:02:01.213922Z","iopub.execute_input":"2025-11-17T19:02:01.214675Z","iopub.status.idle":"2025-11-17T19:02:01.308028Z","shell.execute_reply.started":"2025-11-17T19:02:01.214651Z","shell.execute_reply":"2025-11-17T19:02:01.307296Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Train Standard Model","metadata":{}},{"cell_type":"code","source":"def train_standard_model(x_train, y_train, norm_mean, norm_std, device='cuda'):\n    \"\"\"Train standard model using ART's fit method.\"\"\"\n\n    # Create model\n    model = SimpleCNN(num_classes=10)\n    model.apply(init_model_weights)\n    model = model.to(device)\n\n    # Create classifier\n    classifier = create_classifier(model, norm_mean, norm_std, device)\n\n    # Train using ART's fit method\n    print(\"Training standard model...\")\n    classifier.fit(x_train, y_train, batch_size=128, nb_epochs=10)\n\n    print(\"Standard model training completed!\")\n    return classifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T19:03:01.113952Z","iopub.execute_input":"2025-11-17T19:03:01.114819Z","iopub.status.idle":"2025-11-17T19:03:01.120018Z","shell.execute_reply.started":"2025-11-17T19:03:01.114770Z","shell.execute_reply":"2025-11-17T19:03:01.119083Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"standard_classifier = train_standard_model(\n    x_train, y_train, norm_mean, norm_std, device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T19:03:01.448708Z","iopub.execute_input":"2025-11-17T19:03:01.449332Z","iopub.status.idle":"2025-11-17T19:03:17.170615Z","shell.execute_reply.started":"2025-11-17T19:03:01.449305Z","shell.execute_reply":"2025-11-17T19:03:17.169900Z"}},"outputs":[{"name":"stdout","text":"Training standard model...\nStandard model training completed!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Train Adversarial Model","metadata":{}},{"cell_type":"code","source":"def train_adversarial_model(x_train, y_train, norm_mean, norm_std, device='cuda'):\n    \"\"\"Train adversarial model using AdversarialTrainerFBFPyTorch.\"\"\"\n    \n    # Create model\n    model = SimpleCNN(num_classes=10)\n    model.apply(init_model_weights)\n    model = model.to(device)\n    \n    # Create classifier\n    classifier = create_classifier(model, norm_mean, norm_std, device)\n    \n    # Create adversarial trainer\n    adv_trainer = AdversarialTrainerFBFPyTorch(\n        classifier, \n        eps=8.0/255.0,\n        use_amp=False\n    )\n    \n    # Train with adversarial examples\n    print(\"Training adversarial model...\")\n    adv_trainer.fit(x_train, y_train, batch_size=128, nb_epochs=10)\n    \n    print(\"Adversarial model training completed!\")\n    return classifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T19:03:34.366664Z","iopub.execute_input":"2025-11-17T19:03:34.367508Z","iopub.status.idle":"2025-11-17T19:03:34.373029Z","shell.execute_reply.started":"2025-11-17T19:03:34.367482Z","shell.execute_reply":"2025-11-17T19:03:34.372111Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"adversarial_classifier = train_adversarial_model(\n    x_train, y_train, norm_mean, norm_std, device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T19:03:34.546072Z","iopub.execute_input":"2025-11-17T19:03:34.546861Z","iopub.status.idle":"2025-11-17T19:04:55.083503Z","shell.execute_reply.started":"2025-11-17T19:03:34.546837Z","shell.execute_reply":"2025-11-17T19:04:55.081916Z"}},"outputs":[{"name":"stdout","text":"Training adversarial model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Adversarial Training FBF - Epochs:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc31a1d1967f4dda80f40008f5c4b0f2"}},"metadata":{}},{"name":"stdout","text":"Adversarial model training completed!\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Evaluate Models","metadata":{}},{"cell_type":"code","source":"def evaluate_models(standard_classifier, adversarial_classifier, x_test, y_test):\n    \"\"\"Evaluate both models on clean and adversarial data.\"\"\"\n    \n    # Standard model\n    standard_preds = standard_classifier.predict(x_test)\n    standard_accuracy = np.sum(np.argmax(standard_preds, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n    print(f\"Standard Model Clean Accuracy: {standard_accuracy * 100:.2f}%\")\n    \n    # Adversarial model\n    adversarial_preds = adversarial_classifier.predict(x_test)\n    adversarial_accuracy = np.sum(np.argmax(adversarial_preds, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n    print(f\"Adversarial Model Clean Accuracy: {adversarial_accuracy * 100:.2f}%\")\n    \n    # Create separate PGD attacks for each model\n    print(\"Generating adversarial examples for standard model...\")\n    pgd_attack_standard = ProjectedGradientDescent(\n        estimator=standard_classifier,\n        norm=np.inf,\n        eps=8.0/255.0,\n        eps_step=2.0/255.0,\n        max_iter=10,\n        targeted=False,\n        num_random_init=1,\n        batch_size=128\n    )\n    \n    # Generate adversarial examples for standard model\n    x_test_adv_standard = pgd_attack_standard.generate(x_test)\n    \n    # Evaluate standard model on adversarial examples\n    standard_adv_preds = standard_classifier.predict(x_test_adv_standard)\n    standard_adv_accuracy = np.sum(np.argmax(standard_adv_preds, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n    print(f\"Standard Model Adversarial Accuracy: {standard_adv_accuracy * 100:.2f}%\")\n    \n    # Create separate PGD attack for adversarial model\n    print(\"Generating adversarial examples for adversarial model...\")\n    pgd_attack_adversarial = ProjectedGradientDescent(\n        estimator=adversarial_classifier,\n        norm=np.inf,\n        eps=8.0/255.0,\n        eps_step=2.0/255.0,\n        max_iter=10,\n        targeted=False,\n        num_random_init=1,\n        batch_size=128\n    )\n    \n    # Generate adversarial examples for adversarial model\n    x_test_adv_adversarial = pgd_attack_adversarial.generate(x_test)\n    \n    # Evaluate adversarial model on adversarial examples\n    adversarial_adv_preds = adversarial_classifier.predict(x_test_adv_adversarial)\n    adversarial_adv_accuracy = np.sum(np.argmax(adversarial_adv_preds, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n    print(f\"Adversarial Model Adversarial Accuracy: {adversarial_adv_accuracy * 100:.2f}%\")\n    \n    return {\n        'standard_clean': standard_accuracy * 100,\n        'adversarial_clean': adversarial_accuracy * 100,\n        'standard_adv': standard_adv_accuracy * 100,\n        'adversarial_adv': adversarial_adv_accuracy * 100\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T19:05:05.489663Z","iopub.execute_input":"2025-11-17T19:05:05.489966Z","iopub.status.idle":"2025-11-17T19:05:05.498713Z","shell.execute_reply.started":"2025-11-17T19:05:05.489945Z","shell.execute_reply":"2025-11-17T19:05:05.497938Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"results = evaluate_models(standard_classifier, adversarial_classifier, x_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T19:05:07.515998Z","iopub.execute_input":"2025-11-17T19:05:07.516760Z","iopub.status.idle":"2025-11-17T19:05:24.875951Z","shell.execute_reply.started":"2025-11-17T19:05:07.516730Z","shell.execute_reply":"2025-11-17T19:05:24.875193Z"}},"outputs":[{"name":"stdout","text":"Standard Model Clean Accuracy: 74.60%\nAdversarial Model Clean Accuracy: 62.09%\nGenerating adversarial examples for standard model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"PGD - Batches:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Standard Model Adversarial Accuracy: 12.19%\nGenerating adversarial examples for adversarial model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"PGD - Batches:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adversarial Model Adversarial Accuracy: 45.33%\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"print(\"=\"*50)\nprint(\"FINAL SUMMARY\")\nprint(\"=\"*50)\nprint(f\"Standard Model:\")\nprint(f\"Clean Accuracy:       {results['standard_clean']:.2f}%\")\nprint(f\"Adversarial Accuracy: {results['standard_adv']:.2f}%\")\nprint(f\"Robustness Drop:      {results['standard_clean'] - results['standard_adv']:.2f}%\")\n\nprint(f\"\\nAdversarial Model:\")\nprint(f\"Clean Accuracy:       {results['adversarial_clean']:.2f}%\")\nprint(f\"Adversarial Accuracy: {results['adversarial_adv']:.2f}%\")\nprint(f\"Robustness Drop:      {results['adversarial_clean'] - results['adversarial_adv']:.2f}%\")\n\nrobustness_improvement = results['adversarial_adv'] - results['standard_adv']\nprint(f\"\\nRobustness Improvement: +{robustness_improvement:.2f}%\")\n\nclean_performance_drop = results['standard_clean'] - results['adversarial_clean']\nprint(f\"Clean Performance Drop: {clean_performance_drop:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T19:07:31.517898Z","iopub.execute_input":"2025-11-17T19:07:31.518290Z","iopub.status.idle":"2025-11-17T19:07:31.525048Z","shell.execute_reply.started":"2025-11-17T19:07:31.518266Z","shell.execute_reply":"2025-11-17T19:07:31.524200Z"}},"outputs":[{"name":"stdout","text":"==================================================\nFINAL SUMMARY\n==================================================\nStandard Model:\nClean Accuracy:       74.60%\nAdversarial Accuracy: 12.19%\nRobustness Drop:      62.41%\n\nAdversarial Model:\nClean Accuracy:       62.09%\nAdversarial Accuracy: 45.33%\nRobustness Drop:      16.76%\n\nRobustness Improvement: +33.14%\nClean Performance Drop: 12.51%\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}